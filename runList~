hadoop-2.7.0/bin/hdfs dfs -rmr -skipTrash /home/asadani/rampup/output*
hadoop-2.7.0/bin/hdfs dfs -rm -skipTrash /home/asadani/rampup/input/*
hadoop-2.7.0/bin/hdfs dfs -copyFromLocal ../user-traffic.log /home/asadani/rampup/input

 



hadoop-2.7.0/bin/hadoop jar /home/IMPETUS/asadani/codebase/rampup/sandbox/data-flattener/target/data-flattener-0.0.1-SNAPSHOT.jar com.asadani.flattener.JSONDataFlattener /home/asadani/rampup/input/user-traffic.log /home/asadani/rampup/output/


mvn exec:java


http://stackoverflow.com/questions/29784532/pig-keeps-trying-to-connect-to-job-history-server-and-fails


<property>
<name>mapreduce.jobhistory.address</name>
<value>cm:10020</value>
<description>Host and port for Job History Server (default 0.0.0.0:10020)</description>
</property>

ps ax | grep -e JobHistory

/home/asadani/rampup/output/days

0.154.253.186,1444501382355,5208,POST,user/register,example,asdf

A = load '/home/asadani/rampup/output/days/10/21_927-r-00021' USING PigStorage(',') AS (clientIPAddress:bytearray, timestamp:bytearray, zipcode:bytearray, httpMethod:bytearray, httpURL:bytearray, userId:bytearray, userAuthToken:bytearray, eventDate:int, eventMonth:int, eventYear:int);

===============WORKING================

FLAT_DATA = load '/home/asadani/rampup/output/days/*' USING PigStorage(',') AS (clientIPAddress:chararray, timestamp:chararray, zipcode:chararray, httpMethod:chararray, httpURL:chararray, userId:chararray, userAuthToken:chararray, eventDate:chararray, eventMonth:chararray, eventYear:chararray);

FLAT_DATA_WITH_DATE = foreach FLAT_DATA generate clientIPAddress, timestamp, zipcode, httpMethod, httpURL, userId, userAuthToken, CONCAT(CONCAT(CONCAT((chararray)eventDate, '-'), (chararray)eventMonth, '-'), (chararray)eventYear) AS eventDateCon:chararray;

GROUPED_BY_DAY = GROUP FLAT_DATA_WITH_DATE BY eventDateCon;

COUNT_HITS_BY_DAY = FOREACH GROUPED_BY_DAY GENERATE group as myVar, COUNT(FLAT_DATA_WITH_DATE) as countForDay;

COUNT_HITS_BY_DAY_SUMMARY = FOREACH COUNT_HITS_BY_DAY GENERATE (chararray)myVar as day, (int)countForDay as count;

ILLUSTRATE COUNT_HITS_BY_DAY_SUMMARY;

===============WORKING================

<dependency>
	<groupId>org.cloudera.htrace</groupId>
	<artifactId>htrace-core</artifactId>
	<version>2.05</version>
</dependency>

 export HADOOP_CLASSPATH=$CLASSPATH:/home/IMPETUS/asadani/codebase/rampup/sandbox/data-generator/target/lib/htrace-core-2.05.jar:$HADOOP_CLASSPATH

		

STORE COUNT_HITS_BY_DAY_SUMMARY INTO 'hbase://pig_table' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage ('cf:count');


PIG_CLASSPATH=/usr/lib/hbase/hbase.jar:/usr/lib/zookeeper/zookeeper-3.4.5-cdh4.4.0.jar /usr/bin/pig /home/training/Load_HBase_Customers.pig







B = GROUP A BY userAuthToken;

C = FOREACH B {
SESSION_ACTIVITY = ORDER A BY timestamp;
GENERATE SESSION_ACTIVITY, COUNT(A);
};


hadoop-2.7.0/sbin/mr-jobhistory-daemon.sh start historyserver


======================================

Most visited pages by users

create 'MOST_VISITED_PAGES_BY_USERS', 'count'



FLAT_DATA = load '/home/asadani/rampup/output/days/*' USING PigStorage(',') AS (clientIPAddress:chararray, timestamp:chararray, zipcode:chararray, httpMethod:chararray, httpURL:chararray, userId:chararray, userAuthToken:chararray, eventDate:chararray, eventMonth:chararray, eventYear:chararray);

FLAT_DATA_FILTERED = FILTER FLAT_DATA BY (httpURL matches 'view/home' or httpURL matches 'view/product' or httpURL matches 'view/category');


FLAT_DATA_WITH_MONTH = foreach FLAT_DATA_FILTERED generate clientIPAddress, timestamp, zipcode, httpMethod, httpURL, userId, userAuthToken, CONCAT(CONCAT((chararray)eventMonth, '-'), (chararray)eventYear) AS eventMonthCon:chararray;

GROUPED_BY_MONTH_PAGE = GROUP FLAT_DATA_WITH_MONTH BY (eventMonthCon, httpURL);

COUNT_HITS_PER_PAGE_BY_MONTH = FOREACH GROUPED_BY_MONTH_PAGE GENERATE group as groupKey, COUNT(FLAT_DATA_WITH_MONTH) as countForMonth;

COUNT_HITS_PER_PAGE_BY_MONTH_SUMMARY = FOREACH COUNT_HITS_PER_PAGE_BY_MONTH GENERATE groupKey, (int)countForMonth as count;

STORE COUNT_HITS_PER_PAGE_BY_MONTH_SUMMARY INTO 'hbase://MOST_VISITED_PAGES_BY_USERS' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage ('count:count');







sudo service mysql start

ln -s /usr/share/java/mysql-connector-java-5.1.28.jar /home/IMPETUS/asadani/Installs/apache-hive-1.2.1-bin/lib/mysql-connector-java-5.1.28.jar

/home/IMPETUS/asadani/Installs/apache-hive-1.2.1-bin/lib

SOURCE /home/IMPETUS/asadani/Installs/apache-hive-1.2.1-bin/scripts/metastore/upgrade/mysql/hive-schema-0.10.0.mysql.sql;

CREATE USER 'hive'@'localhost' IDENTIFIED BY 'hive';

REVOKE ALL PRIVILEGES, GRANT OPTION FROM 'hive'@'localhost';

GRANT SELECT,INSERT,UPDATE,DELETE,LOCK TABLES,EXECUTE ON metastore.* TO 'hive'@'localhost';













$ sudo chkconfig mysql on



12557 dressing
6642 loft
33260 wardrobe









CREATE TABLE u_data (
  userid INT,
  movieid INT,
  rating INT,
  unixtime STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE;

LOAD DATA LOCAL INPATH '/home/IMPETUS/asadani/Installs/ml-100k/u.data' OVERWRITE INTO TABLE u_data;


CREATE TABLE moviedetails_data (
movieid int, movietitle String, release_date String, video_release_date String, ImdbURL String, genreunknown int, Action int, Adventure int, Animation int, Childrens int, Comedy int, Crime int, Documentary int, Drama int, Fantasy int, Film_Noir int, Horror int, Musical int, Mystery int, Romance int, SciFi int, Thriller int, War int, Western int)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|'
STORED AS TEXTFILE;

LOAD DATA LOCAL INPATH '/home/IMPETUS/asadani/Installs/ml-100k/u.item' OVERWRITE INTO TABLE moviedetails_data;

CREATE TABLE userdetails_data (
userid int, age int, gender String, occupation String, zip_code String)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '|'
STORED AS TEXTFILE;

LOAD DATA LOCAL INPATH '/home/IMPETUS/asadani/Installs/ml-100k/u.user' OVERWRITE INTO TABLE userdetails_data;

--CREATE TABLE movie_rating_count(rating_count int, movieid String);

--INSERT OVERWRITE TABLE movie_rating_count select count(*) rating_count, movieid from u_data group by movieid;

--select * from movie_rating_count order by rating_count desc limit 50;

--select movietitle, rating_count from movie_rating_count mrc, moviedetails_data md where mrc.movieid = md.movieid order by rating_count desc limit 50;

select movietitle, rating_count from (select count(*) rating_count, movieid from u_data group by movieid having count(*) > 250) inner_data, moviedetails_data md where inner_data.movieid = md.movieid order by rating_count desc;

select count(*) rating_count, userid from u_data group by userid having count(*) > 50 order by rating_count;

select count(*) rating_count, userid from u_data group by userid order by rating_count;


/home/asadani/rampup/movielens/u.data
/home/asadani/rampup/movielens/u.user
/home/asadani/rampup/movielens/u.item


RATING_DATA = load '/home/asadani/rampup/movielens/u.data' USING PigStorage('\t') AS (userid:int, movieid:int, rating:int, timeunix:chararray);

USER_DATA = load '/home/asadani/rampup/movielens/u.user' USING PigStorage('|') AS (userid:int, movieid:int, rating:int, timeunix:chararray);

MOVIE_DATA = load '/home/asadani/rampup/movielens/u.item' USING PigStorage('|') AS (movieid:int, movietitle:chararray, release_date:chararray, video_release_date:chararray, ImdbURL:chararray, genreunknown:int, Action:int, Adventure:int, Animation:int, Childrens:int, Comedy:int, Crime:int, Documentary:int, Drama:int, Fantasy:int, Film_Noir:int, Horror:int, Musical:int, Mystery:int, Romance:int, SciFi:int, Thriller:int, War:int, Western:int);

===============================================================

USER_RATING = GROUP RATING_DATA BY userid;

describe USER_RATING;

USER_RATING_SUMMARY = FOREACH USER_RATING generate group, SUM(RATING_DATA.rating) as rating_sum;

USER_RATING_SUMMARY_ORDERED = ORDER USER_RATING_SUMMARY BY rating_sum;

dump USER_RATING_SUMMARY_ORDERED;


===============================================================

MOVIE_RATING = GROUP RATING_DATA BY movieid;

MOVIE_RATING_SUMMARY = FOREACH MOVIE_RATING generate group, SUM(RATING_DATA.rating) as rating_sum;

MOVIE_RATING_SUMMARY_ORDERED = ORDER MOVIE_RATING_SUMMARY BY rating_sum DESC;

MOVIE_RATING_SUMMARY_ORDERED_WITH_MOVIE_DETAILS = JOIN MOVIE_DATA BY movieid, MOVIE_RATING_SUMMARY_ORDERED BY group;

FINAL_OUTPUT = FOREACH MOVIE_RATING_SUMMARY_ORDERED_WITH_MOVIE_DETAILS GENERATE movietitle, rating_sum;

=================================================================================

